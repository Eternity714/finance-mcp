"""
Redisç¼“å­˜ç®¡ç†å™¨
ä¸“é—¨ä¸ºAKShareå…¨å¸‚åœºæ•°æ®å’ŒåŸºæœ¬é¢æ•°æ®æä¾›é«˜æ€§èƒ½ç¼“å­˜
"""

import redis
import pickle
import time
import pandas as pd
from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta
import logging
import json
import hashlib

logger = logging.getLogger(__name__)


class RedisCache:
    """Redisç¼“å­˜ç®¡ç†å™¨"""

    def __init__(self, host="localhost", port=6379, db=0, decode_responses=False):
        """
        åˆå§‹åŒ–Redisè¿æ¥

        Args:
            host: Redisä¸»æœºåœ°å€
            port: Redisç«¯å£
            db: Redisæ•°æ®åº“ç¼–å·
            decode_responses: æ˜¯å¦è‡ªåŠ¨è§£ç å“åº”ï¼ˆDataFrameéœ€è¦è®¾ä¸ºFalseï¼‰
        """
        try:
            self.redis_client = redis.Redis(
                host=host,
                port=port,
                db=db,
                decode_responses=decode_responses,
                socket_connect_timeout=5,
                socket_timeout=5,
            )

            # æµ‹è¯•è¿æ¥
            self.redis_client.ping()
            self.connected = True
            logger.info(f"âœ… Redisè¿æ¥æˆåŠŸ: {host}:{port}")

        except Exception as e:
            self.connected = False
            logger.error(f"âŒ Redisè¿æ¥å¤±è´¥: {e}")
            logger.warning("ğŸ”„ å°†ä½¿ç”¨å†…å­˜ç¼“å­˜ä½œä¸ºé™çº§æ–¹æ¡ˆ")
            self._memory_cache = {}

    def _get_cache_key(self, prefix: str, identifier: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return f"stock_srv:{prefix}:{identifier}"

    def _serialize_dataframe(self, df: pd.DataFrame) -> bytes:
        """åºåˆ—åŒ–DataFrame"""
        return pickle.dumps(df)

    def _deserialize_dataframe(self, data: bytes) -> pd.DataFrame:
        """ååºåˆ—åŒ–DataFrame"""
        return pickle.loads(data)

    def set_market_data(self, data: pd.DataFrame, expire_seconds: int = 86400) -> bool:
        """
        ç¼“å­˜å…¨å¸‚åœºæ•°æ®

        Args:
            data: å…¨å¸‚åœºè‚¡ç¥¨æ•°æ®DataFrame
            expire_seconds: ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            bool: æ˜¯å¦ç¼“å­˜æˆåŠŸ
        """
        try:
            if not self.connected:
                # é™çº§åˆ°å†…å­˜ç¼“å­˜
                self._memory_cache["market_data"] = {
                    "data": data,
                    "timestamp": time.time(),
                    "expire_seconds": expire_seconds,
                }
                logger.info("ğŸ“ å…¨å¸‚åœºæ•°æ®å·²ç¼“å­˜åˆ°å†…å­˜")
                return True

            cache_key = self._get_cache_key("market", "all_stocks")
            serialized_data = self._serialize_dataframe(data)

            # ä½¿ç”¨Redis pipelineæé«˜æ€§èƒ½
            pipe = self.redis_client.pipeline()
            pipe.set(cache_key, serialized_data)
            pipe.expire(cache_key, expire_seconds)

            # åŒæ—¶ç¼“å­˜å…ƒæ•°æ®
            metadata = {
                "total_stocks": len(data),
                "columns": list(data.columns),
                "cached_at": datetime.now().isoformat(),
                "expire_seconds": expire_seconds,
            }
            metadata_key = self._get_cache_key("market", "metadata")
            pipe.set(metadata_key, json.dumps(metadata))
            pipe.expire(metadata_key, expire_seconds)

            pipe.execute()

            logger.info(
                f"âœ… å…¨å¸‚åœºæ•°æ®å·²ç¼“å­˜åˆ°Redis: {len(data)}åªè‚¡ç¥¨ï¼Œè¿‡æœŸæ—¶é—´{expire_seconds}ç§’"
            )
            return True

        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜å…¨å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            return False

    def get_market_data(self) -> Optional[pd.DataFrame]:
        """
        è·å–ç¼“å­˜çš„å…¨å¸‚åœºæ•°æ®

        Returns:
            Optional[pd.DataFrame]: å…¨å¸‚åœºæ•°æ®ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨æˆ–è¿‡æœŸåˆ™è¿”å›None
        """
        try:
            if not self.connected:
                # ä»å†…å­˜ç¼“å­˜è·å–
                cached = self._memory_cache.get("market_data")
                if cached:
                    now = time.time()
                    if now - cached["timestamp"] < cached["expire_seconds"]:
                        logger.info("ğŸ“– ä»å†…å­˜ç¼“å­˜è·å–å…¨å¸‚åœºæ•°æ®")
                        return cached["data"]
                    else:
                        del self._memory_cache["market_data"]
                        logger.info("â° å†…å­˜ç¼“å­˜å·²è¿‡æœŸ")
                return None

            cache_key = self._get_cache_key("market", "all_stocks")
            cached_data = self.redis_client.get(cache_key)

            if cached_data:
                df = self._deserialize_dataframe(cached_data)
                logger.info(f"ğŸ“– ä»Redisç¼“å­˜è·å–å…¨å¸‚åœºæ•°æ®: {len(df)}åªè‚¡ç¥¨")
                return df
            else:
                logger.info("ğŸ’¾ Redisç¼“å­˜ä¸­æ— å…¨å¸‚åœºæ•°æ®")
                return None

        except Exception as e:
            logger.error(f"âŒ è·å–ç¼“å­˜å…¨å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            return None

    def get_stock_from_market_cache(self, symbol: str) -> Optional[pd.Series]:
        """
        ä»ç¼“å­˜çš„å…¨å¸‚åœºæ•°æ®ä¸­è·å–å•åªè‚¡ç¥¨æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼ˆä¸å«äº¤æ˜“æ‰€åç¼€ï¼‰

        Returns:
            Optional[pd.Series]: è‚¡ç¥¨æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            market_data = self.get_market_data()
            if market_data is None or market_data.empty:
                return None

            # æŸ¥æ‰¾è‚¡ç¥¨æ•°æ®
            stock_data = market_data[market_data["ä»£ç "] == symbol]
            if not stock_data.empty:
                logger.info(f"ğŸ¯ ä»å¸‚åœºç¼“å­˜ä¸­æ‰¾åˆ°è‚¡ç¥¨ {symbol}")
                return stock_data.iloc[0]
            else:
                logger.info(f"ğŸ” å¸‚åœºç¼“å­˜ä¸­æœªæ‰¾åˆ°è‚¡ç¥¨ {symbol}")
                return None

        except Exception as e:
            logger.error(f"âŒ ä»å¸‚åœºç¼“å­˜è·å–è‚¡ç¥¨{symbol}å¤±è´¥: {e}")
            return None

    def set_fundamental_data(
        self, symbol: str, data: Dict[str, Any], expire_seconds: int = 86400
    ) -> bool:
        """
        ç¼“å­˜åŸºæœ¬é¢æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data: åŸºæœ¬é¢æ•°æ®å­—å…¸
            expire_seconds: ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1å°æ—¶

        Returns:
            bool: æ˜¯å¦ç¼“å­˜æˆåŠŸ
        """
        try:
            if not self.connected:
                return False

            cache_key = self._get_cache_key("fundamental", symbol)

            # æ·»åŠ ç¼“å­˜æ—¶é—´æˆ³
            data_with_meta = {
                "data": data,
                "cached_at": datetime.now().isoformat(),
                "symbol": symbol,
            }

            self.redis_client.setex(
                cache_key,
                expire_seconds,
                json.dumps(data_with_meta, ensure_ascii=False),
            )

            logger.info(f"âœ… åŸºæœ¬é¢æ•°æ®å·²ç¼“å­˜: {symbol}ï¼Œè¿‡æœŸæ—¶é—´{expire_seconds}ç§’")
            return True

        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜åŸºæœ¬é¢æ•°æ®å¤±è´¥ {symbol}: {e}")
            return False

    def get_fundamental_data(self, symbol: str) -> Optional[Dict[str, Any]]:
        """
        è·å–ç¼“å­˜çš„åŸºæœ¬é¢æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            Optional[Dict]: åŸºæœ¬é¢æ•°æ®ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨æˆ–è¿‡æœŸåˆ™è¿”å›None
        """
        try:
            if not self.connected:
                return None

            cache_key = self._get_cache_key("fundamental", symbol)
            cached_data = self.redis_client.get(cache_key)

            if cached_data:
                data_with_meta = json.loads(cached_data)
                logger.info(f"ğŸ“– ä»Redisè·å–åŸºæœ¬é¢ç¼“å­˜: {symbol}")
                return data_with_meta["data"]
            else:
                logger.info(f"ğŸ’¾ Redisä¸­æ— åŸºæœ¬é¢ç¼“å­˜: {symbol}")
                return None

        except Exception as e:
            logger.error(f"âŒ è·å–åŸºæœ¬é¢ç¼“å­˜å¤±è´¥ {symbol}: {e}")
            return None

    def cache_stock_info(
        self, symbol: str, info: Dict[str, Any], expire_seconds: int = 86400
    ) -> bool:
        """ç¼“å­˜è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        try:
            if not self.connected:
                return False

            cache_key = self._get_cache_key("info", symbol)
            self.redis_client.setex(
                cache_key, expire_seconds, json.dumps(info, ensure_ascii=False)
            )
            return True
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜è‚¡ç¥¨ä¿¡æ¯å¤±è´¥ {symbol}: {e}")
            return False

    def get_stock_info(self, symbol: str) -> Optional[Dict[str, Any]]:
        """è·å–ç¼“å­˜çš„è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        try:
            if not self.connected:
                return None

            cache_key = self._get_cache_key("info", symbol)
            cached_data = self.redis_client.get(cache_key)

            if cached_data:
                return json.loads(cached_data)
            return None
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨ä¿¡æ¯ç¼“å­˜å¤±è´¥ {symbol}: {e}")
            return None

    def clear_cache(self, pattern: str = "stock_srv:*") -> int:
        """
        æ¸…é™¤ç¼“å­˜

        Args:
            pattern: ç¼“å­˜é”®æ¨¡å¼ï¼Œé»˜è®¤æ¸…é™¤æ‰€æœ‰stock_srvç›¸å…³ç¼“å­˜

        Returns:
            int: æ¸…é™¤çš„ç¼“å­˜æ•°é‡
        """
        try:
            if not self.connected:
                cleared = len(self._memory_cache)
                self._memory_cache.clear()
                logger.info(f"ğŸ§¹ æ¸…é™¤å†…å­˜ç¼“å­˜: {cleared}é¡¹")
                return cleared

            keys = self.redis_client.keys(pattern)
            if keys:
                deleted = self.redis_client.delete(*keys)
                logger.info(f"ğŸ§¹ æ¸…é™¤Redisç¼“å­˜: {deleted}é¡¹")
                return deleted
            else:
                logger.info("ğŸ§¹ æ— ç¼“å­˜éœ€è¦æ¸…é™¤")
                return 0

        except Exception as e:
            logger.error(f"âŒ æ¸…é™¤ç¼“å­˜å¤±è´¥: {e}")
            return 0

    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        try:
            if not self.connected:
                return {
                    "type": "memory",
                    "connected": False,
                    "memory_cache_size": len(self._memory_cache),
                }

            info = self.redis_client.info()

            # è·å–stock_srvç›¸å…³çš„é”®æ•°é‡
            stock_keys = self.redis_client.keys("stock_srv:*")

            return {
                "type": "redis",
                "connected": True,
                "redis_version": info.get("redis_version"),
                "used_memory": info.get("used_memory_human"),
                "total_keys": (
                    info.get("db0", {}).get("keys", 0) if "db0" in info else 0
                ),
                "stock_srv_keys": len(stock_keys),
                "uptime_seconds": info.get("uptime_in_seconds"),
            }

        except Exception as e:
            logger.error(f"âŒ è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
            return {"type": "unknown", "connected": False, "error": str(e)}

    def exists(self, key: str) -> bool:
        """æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨"""
        try:
            if not self.connected:
                return False
            return bool(self.redis_client.exists(key))
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥é”®å­˜åœ¨å¤±è´¥: {e}")
            return False

    def get_ttl(self, key: str) -> int:
        """è·å–é”®çš„TTL"""
        try:
            if not self.connected:
                return -2
            return self.redis_client.ttl(key)
        except Exception as e:
            logger.error(f"âŒ è·å–TTLå¤±è´¥: {e}")
            return -2


# å…¨å±€ç¼“å­˜å®ä¾‹
_redis_cache = None


def get_redis_cache() -> RedisCache:
    """è·å–Redisç¼“å­˜å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _redis_cache
    if _redis_cache is None:
        _redis_cache = RedisCache()
    return _redis_cache


class AKShareMarketCache:
    """AKShareå¤šå¸‚åœºæ•°æ®ç¼“å­˜ç®¡ç†å™¨ï¼ˆä¸“é—¨ä¼˜åŒ–æ€§èƒ½ï¼‰"""

    def __init__(self, cache_duration: int = 86400):
        """
        åˆå§‹åŒ–AKShareå¸‚åœºæ•°æ®ç¼“å­˜

        Args:
            cache_duration: ç¼“å­˜æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤24å°æ—¶
        """
        self.redis_cache = get_redis_cache()
        self.cache_duration = cache_duration

        # ä¸åŒå¸‚åœºçš„ç¼“å­˜é”®
        self.cache_keys = {
            "china": "akshare:market_data:china_stocks",
            "hk": "akshare:market_data:hk_stocks",
            "us": "akshare:market_data:us_stocks",
        }

        # ä¸åŒå¸‚åœºçš„è·å–æ—¶é—´å’Œå†…å­˜å¤‡ä»½
        self._last_fetch_time = {"china": 0, "hk": 0, "us": 0}
        self._memory_backup = {"china": None, "hk": None, "us": None}

    def get_china_market_data(self) -> Optional[pd.DataFrame]:
        """
        è·å–Aè‚¡å…¨å¸‚åœºæ•°æ®ï¼ˆä¼˜å…ˆä»ç¼“å­˜ï¼‰

        Returns:
            DataFrame: Aè‚¡å…¨å¸‚åœºè‚¡ç¥¨æ•°æ®
        """
        return self._get_market_data_by_type("china")

    def get_hk_market_data(self) -> Optional[pd.DataFrame]:
        """
        è·å–æ¸¯è‚¡å…¨å¸‚åœºæ•°æ®ï¼ˆä¼˜å…ˆä»ç¼“å­˜ï¼‰

        Returns:
            DataFrame: æ¸¯è‚¡å…¨å¸‚åœºè‚¡ç¥¨æ•°æ®
        """
        return self._get_market_data_by_type("hk")

    def get_us_market_data(self) -> Optional[pd.DataFrame]:
        """
        è·å–ç¾è‚¡å…¨å¸‚åœºæ•°æ®ï¼ˆä¼˜å…ˆä»ç¼“å­˜ï¼‰

        Returns:
            DataFrame: ç¾è‚¡å…¨å¸‚åœºè‚¡ç¥¨æ•°æ®
        """
        return self._get_market_data_by_type("us")

    def _get_market_data_by_type(self, market_type: str) -> Optional[pd.DataFrame]:
        """
        é€šç”¨çš„å¸‚åœºæ•°æ®è·å–æ–¹æ³•

        Args:
            market_type: å¸‚åœºç±»å‹ ("china", "hk", "us")

        Returns:
            DataFrame: å¯¹åº”å¸‚åœºçš„è‚¡ç¥¨æ•°æ®
        """
        cache_key = self.cache_keys[market_type]

        # å…ˆå°è¯•ä»Redisç¼“å­˜è·å–
        cached_data = self._get_market_data_from_redis(cache_key)
        if cached_data is not None:
            market_name = {"china": "Aè‚¡", "hk": "æ¸¯è‚¡", "us": "ç¾è‚¡"}[market_type]
            logger.info(
                f"ğŸ“‹ ä½¿ç”¨Redisç¼“å­˜çš„{market_name}æ•°æ®: {len(cached_data)}åªè‚¡ç¥¨"
            )
            self._memory_backup[market_type] = cached_data  # æ›´æ–°å†…å­˜å¤‡ä»½
            return cached_data

        # Redisç¼“å­˜æœªå‘½ä¸­ï¼Œæ£€æŸ¥å†…å­˜å¤‡ä»½
        current_time = time.time()
        if (
            self._memory_backup[market_type] is not None
            and current_time - self._last_fetch_time[market_type] < self.cache_duration
        ):
            market_name = {"china": "Aè‚¡", "hk": "æ¸¯è‚¡", "us": "ç¾è‚¡"}[market_type]
            logger.info(
                f"ğŸ“‹ ä½¿ç”¨å†…å­˜å¤‡ä»½çš„{market_name}æ•°æ®: {len(self._memory_backup[market_type])}åªè‚¡ç¥¨"
            )
            return self._memory_backup[market_type]

        # æ‰€æœ‰ç¼“å­˜éƒ½æœªå‘½ä¸­ï¼Œä»AKShareè·å–æ•°æ®
        return self._fetch_fresh_data_by_type(market_type)

    def _get_market_data_from_redis(self, cache_key: str) -> Optional[pd.DataFrame]:
        """ä»Redisè·å–å¸‚åœºæ•°æ®"""
        try:
            if not self.redis_cache.connected:
                return None

            cached_data = self.redis_cache.redis_client.get(cache_key)
            if cached_data:
                return self.redis_cache._deserialize_dataframe(cached_data)
            return None
        except Exception as e:
            logger.error(f"âŒ ä»Redisè·å–æ•°æ®å¤±è´¥: {e}")
            return None

    def _fetch_fresh_data_by_type(self, market_type: str) -> Optional[pd.DataFrame]:
        """æ ¹æ®å¸‚åœºç±»å‹ä»AKShareè·å–æ–°æ•°æ®"""
        try:
            import akshare as ak

            market_name = {"china": "Aè‚¡", "hk": "æ¸¯è‚¡", "us": "ç¾è‚¡"}[market_type]
            logger.info(f"ğŸ”„ ä»AKShareè·å–{market_name}å…¨å¸‚åœºæ•°æ®...")
            start_time = time.time()

            # æ ¹æ®å¸‚åœºç±»å‹è°ƒç”¨ä¸åŒçš„AKShareæ¥å£
            if market_type == "china":
                market_data = ak.stock_zh_a_spot_em()
            elif market_type == "hk":
                market_data = ak.stock_hk_spot_em()
            elif market_type == "us":
                # ç¾è‚¡æ•°æ® - ä½¿ç”¨ä¸œæ–¹è´¢å¯Œç¾è‚¡å®æ—¶è¡Œæƒ…æ¥å£
                market_data = ak.stock_us_spot_em()
            else:
                logger.error(f"âŒ ä¸æ”¯æŒçš„å¸‚åœºç±»å‹: {market_type}")
                return None

            end_time = time.time()
            duration = end_time - start_time

            if market_data is not None and not market_data.empty:
                # æ›´æ–°ç¼“å­˜æ—¶é—´
                self._last_fetch_time[market_type] = time.time()
                self._memory_backup[market_type] = market_data

                # ç¼“å­˜åˆ°Redis
                if self.redis_cache.connected:
                    self._set_market_data_to_redis(
                        self.cache_keys[market_type], market_data, self.cache_duration
                    )

                logger.info(
                    f"âœ… AKShare {market_name}æ•°æ®è·å–æˆåŠŸ: {len(market_data)}åªè‚¡ç¥¨, "
                    f"è€—æ—¶: {duration:.2f}ç§’"
                )
                return market_data
            else:
                logger.error(f"âŒ AKShareè¿”å›ç©º{market_name}æ•°æ®")
                return self._memory_backup[market_type]  # è¿”å›å†…å­˜å¤‡ä»½

        except Exception as e:
            logger.error(f"âŒ AKShare {market_name}æ•°æ®è·å–å¤±è´¥: {e}")
            return self._memory_backup[market_type]  # è¿”å›å†…å­˜å¤‡ä»½

    def _set_market_data_to_redis(
        self, cache_key: str, data: pd.DataFrame, expire_seconds: int
    ) -> bool:
        """å°†å¸‚åœºæ•°æ®ç¼“å­˜åˆ°Redis"""
        try:
            serialized_data = self.redis_cache._serialize_dataframe(data)

            # ä½¿ç”¨Redis pipelineæé«˜æ€§èƒ½
            pipe = self.redis_cache.redis_client.pipeline()
            pipe.set(cache_key, serialized_data)
            pipe.expire(cache_key, expire_seconds)
            pipe.execute()

            return True
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜å¸‚åœºæ•°æ®åˆ°Rediså¤±è´¥: {e}")
            return False

    def get_china_stock_data(self, symbol: str) -> Optional[dict]:
        """
        ä»ç¼“å­˜çš„Aè‚¡å…¨å¸‚åœºæ•°æ®ä¸­è·å–å•åªè‚¡ç¥¨æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼ˆä¸å¸¦åç¼€ï¼‰

        Returns:
            dict: Aè‚¡è‚¡ç¥¨å¸‚åœºæ•°æ®æˆ–None
        """
        return self._get_stock_data_by_market("china", symbol)

    def get_hk_stock_data(self, symbol: str) -> Optional[dict]:
        """
        ä»ç¼“å­˜çš„æ¸¯è‚¡å…¨å¸‚åœºæ•°æ®ä¸­è·å–å•åªè‚¡ç¥¨æ•°æ®

        Args:
            symbol: æ¸¯è‚¡ä»£ç ï¼ˆä¸å¸¦åç¼€ï¼‰

        Returns:
            dict: æ¸¯è‚¡è‚¡ç¥¨å¸‚åœºæ•°æ®æˆ–None
        """
        return self._get_stock_data_by_market("hk", symbol)

    def get_us_stock_data(self, symbol: str) -> Optional[dict]:
        """
        ä»ç¼“å­˜çš„ç¾è‚¡å…¨å¸‚åœºæ•°æ®ä¸­è·å–å•åªè‚¡ç¥¨æ•°æ®

        Args:
            symbol: ç¾è‚¡ä»£ç 

        Returns:
            dict: ç¾è‚¡è‚¡ç¥¨å¸‚åœºæ•°æ®æˆ–None
        """
        return self._get_stock_data_by_market("us", symbol)

    def _get_stock_data_by_market(
        self, market_type: str, symbol: str
    ) -> Optional[dict]:
        """
        é€šç”¨çš„å•åªè‚¡ç¥¨æ•°æ®è·å–æ–¹æ³•

        Args:
            market_type: å¸‚åœºç±»å‹ ("china", "hk", "us")
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            dict: è‚¡ç¥¨å¸‚åœºæ•°æ®æˆ–None
        """
        # è·å–å¯¹åº”å¸‚åœºçš„å…¨å¸‚åœºæ•°æ®
        if market_type == "china":
            market_data = self.get_china_market_data()
        elif market_type == "hk":
            market_data = self.get_hk_market_data()
        elif market_type == "us":
            market_data = self.get_us_market_data()
        else:
            logger.error(f"âŒ ä¸æ”¯æŒçš„å¸‚åœºç±»å‹: {market_type}")
            return None

        if market_data is None or market_data.empty:
            market_name = {"china": "Aè‚¡", "hk": "æ¸¯è‚¡", "us": "ç¾è‚¡"}[market_type]
            logger.warning(f"âš ï¸ æ— æ³•è·å–{market_name}å…¨å¸‚åœºæ•°æ®")
            return None

        # æŸ¥æ‰¾æŒ‡å®šè‚¡ç¥¨
        try:
            # å¯¹äºç¾è‚¡ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†ä»£ç æ ¼å¼åŒ¹é…
            if market_type == "us":
                # ç¾è‚¡ä»£ç æ ¼å¼ï¼š105.AAPL, 106.MSFT ç­‰
                # å°è¯•å¤šç§åŒ¹é…æ–¹å¼
                pattern = f".{symbol}"
                stock_data = market_data[market_data["ä»£ç "].str.endswith(pattern)]
                if stock_data.empty:
                    # å°è¯•ç›´æ¥åŒ¹é…ï¼ˆç”¨æˆ·å¯èƒ½ä¼ å…¥å®Œæ•´æ ¼å¼ï¼‰
                    stock_data = market_data[market_data["ä»£ç "] == symbol]
            else:
                # Aè‚¡å’Œæ¸¯è‚¡ä½¿ç”¨ç²¾ç¡®åŒ¹é…
                stock_data = market_data[market_data["ä»£ç "] == symbol]

            if stock_data.empty:
                market_name = {"china": "Aè‚¡", "hk": "æ¸¯è‚¡", "us": "ç¾è‚¡"}[market_type]
                if market_type == "us":
                    logger.warning(
                        f"âš ï¸ æœªæ‰¾åˆ°{market_name}è‚¡ç¥¨ {symbol} çš„å¸‚åœºæ•°æ®ï¼Œ"
                        f"å°è¯•è¿‡æ ¼å¼: xxx.{symbol}"
                    )
                else:
                    logger.warning(f"âš ï¸ æœªæ‰¾åˆ°{market_name}è‚¡ç¥¨ {symbol} çš„å¸‚åœºæ•°æ®")
                return None

            # è½¬æ¢ä¸ºå­—å…¸
            stock_info = stock_data.iloc[0].to_dict()
            market_name = {"china": "Aè‚¡", "hk": "æ¸¯è‚¡", "us": "ç¾è‚¡"}[market_type]

            # æ ¹æ®ä¸åŒå¸‚åœºæ˜¾ç¤ºä¸åŒçš„å…³é”®æŒ‡æ ‡
            if market_type == "china":
                pe_info = stock_info.get("å¸‚ç›ˆç‡-åŠ¨æ€", "N/A")
                pb_info = stock_info.get("å¸‚å‡€ç‡", "N/A")
                logger.info(
                    f"âœ… è·å–{market_name}è‚¡ç¥¨æ•°æ®: {symbol} - PE: {pe_info}, PB: {pb_info}"
                )
            else:
                price_info = stock_info.get("æœ€æ–°ä»·", "N/A")
                change_info = stock_info.get("æ¶¨è·Œå¹…", "N/A")
                logger.info(
                    f"âœ… è·å–{market_name}è‚¡ç¥¨æ•°æ®: {symbol} - ä»·æ ¼: {price_info}, æ¶¨è·Œå¹…: {change_info}"
                )

            return stock_info

        except Exception as e:
            market_name = {"china": "Aè‚¡", "hk": "æ¸¯è‚¡", "us": "ç¾è‚¡"}[market_type]
            logger.error(f"âŒ æå–{market_name}è‚¡ç¥¨æ•°æ®å¤±è´¥: {symbol}, é”™è¯¯: {e}")
            return None

    def get_multiple_stocks_data(
        self, market_type: str, symbols: List[str]
    ) -> Dict[str, dict]:
        """
        æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨çš„å¸‚åœºæ•°æ®

        Args:
            market_type: å¸‚åœºç±»å‹ ("china", "hk", "us")
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨

        Returns:
            dict: {symbol: stock_data}
        """
        # è·å–å¯¹åº”å¸‚åœºçš„å…¨å¸‚åœºæ•°æ®
        if market_type == "china":
            market_data = self.get_china_market_data()
        elif market_type == "hk":
            market_data = self.get_hk_market_data()
        elif market_type == "us":
            market_data = self.get_us_market_data()
        else:
            logger.error(f"âŒ ä¸æ”¯æŒçš„å¸‚åœºç±»å‹: {market_type}")
            return {}

        if market_data is None or market_data.empty:
            return {}

        results = {}
        try:
            for symbol in symbols:
                stock_data = market_data[market_data["ä»£ç "] == symbol]
                if not stock_data.empty:
                    results[symbol] = stock_data.iloc[0].to_dict()

            market_name = {"china": "Aè‚¡", "hk": "æ¸¯è‚¡", "us": "ç¾è‚¡"}[market_type]
            logger.info(
                f"âœ… æ‰¹é‡è·å–{market_name}è‚¡ç¥¨æ•°æ®: {len(results)}/{len(symbols)} æˆåŠŸ"
            )
            return results

        except Exception as e:
            market_name = {"china": "Aè‚¡", "hk": "æ¸¯è‚¡", "us": "ç¾è‚¡"}[market_type]
            logger.error(f"âŒ æ‰¹é‡è·å–{market_name}è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
            return {}

    def clear_cache(self, market_type: str = None) -> bool:
        """
        æ¸…é™¤å¸‚åœºæ•°æ®ç¼“å­˜

        Args:
            market_type: å¸‚åœºç±»å‹ï¼ŒNoneè¡¨ç¤ºæ¸…é™¤æ‰€æœ‰å¸‚åœºç¼“å­˜
        """
        if market_type is None:
            # æ¸…é™¤æ‰€æœ‰å¸‚åœºçš„ç¼“å­˜
            success_count = 0
            for mtype in ["china", "hk", "us"]:
                if self._clear_single_market_cache(mtype):
                    success_count += 1
            logger.info(f"ğŸ—‘ï¸ å·²æ¸…é™¤ {success_count}/3 ä¸ªå¸‚åœºçš„ç¼“å­˜æ•°æ®")
            return success_count > 0
        else:
            # æ¸…é™¤æŒ‡å®šå¸‚åœºçš„ç¼“å­˜
            return self._clear_single_market_cache(market_type)

    def _clear_single_market_cache(self, market_type: str) -> bool:
        """æ¸…é™¤å•ä¸ªå¸‚åœºçš„ç¼“å­˜æ•°æ®"""
        try:
            cache_key = self.cache_keys[market_type]

            redis_result = True
            if self.redis_cache.connected:
                redis_result = bool(self.redis_cache.redis_client.delete(cache_key))

            self._memory_backup[market_type] = None
            self._last_fetch_time[market_type] = 0

            market_name = {"china": "Aè‚¡", "hk": "æ¸¯è‚¡", "us": "ç¾è‚¡"}[market_type]
            if redis_result:
                logger.info(f"ğŸ—‘ï¸ {market_name}ç¼“å­˜å·²æ¸…é™¤ï¼ˆRedis + å†…å­˜ï¼‰")
            return redis_result
        except Exception as e:
            logger.error(f"âŒ æ¸…é™¤{market_type}å¸‚åœºç¼“å­˜å¤±è´¥: {e}")
            return False

    def get_cache_info(self, market_type: str = None) -> dict:
        """
        è·å–ç¼“å­˜çŠ¶æ€ä¿¡æ¯

        Args:
            market_type: å¸‚åœºç±»å‹ï¼ŒNoneè¡¨ç¤ºè·å–æ‰€æœ‰å¸‚åœºä¿¡æ¯
        """
        if market_type is None:
            # è¿”å›æ‰€æœ‰å¸‚åœºçš„ç¼“å­˜ä¿¡æ¯
            all_info = {}
            for mtype in ["china", "hk", "us"]:
                all_info[mtype] = self._get_single_market_cache_info(mtype)
            return all_info
        else:
            # è¿”å›æŒ‡å®šå¸‚åœºçš„ç¼“å­˜ä¿¡æ¯
            return self._get_single_market_cache_info(market_type)

    def _get_single_market_cache_info(self, market_type: str) -> dict:
        """è·å–å•ä¸ªå¸‚åœºçš„ç¼“å­˜çŠ¶æ€ä¿¡æ¯"""
        cache_key = self.cache_keys[market_type]
        redis_exists = False
        redis_ttl = -2

        if self.redis_cache.connected:
            try:
                redis_exists = bool(self.redis_cache.redis_client.exists(cache_key))
                if redis_exists:
                    redis_ttl = self.redis_cache.redis_client.ttl(cache_key)
            except Exception as e:
                logger.error(f"âŒ è·å–Redisç¼“å­˜ä¿¡æ¯å¤±è´¥: {e}")

        memory_valid = (
            self._memory_backup[market_type] is not None
            and time.time() - self._last_fetch_time[market_type] < self.cache_duration
        )

        return {
            "market_type": market_type,
            "redis": {
                "exists": redis_exists,
                "ttl": redis_ttl,
                "connected": self.redis_cache.connected,
            },
            "memory": {
                "valid": memory_valid,
                "last_fetch": self._last_fetch_time[market_type],
                "records": (
                    len(self._memory_backup[market_type])
                    if self._memory_backup[market_type] is not None
                    else 0
                ),
            },
            "cache_duration": self.cache_duration,
        }

    def force_refresh(
        self, market_type: str = None
    ) -> Dict[str, Optional[pd.DataFrame]]:
        """
        å¼ºåˆ¶åˆ·æ–°ç¼“å­˜æ•°æ®

        Args:
            market_type: å¸‚åœºç±»å‹ï¼ŒNoneè¡¨ç¤ºåˆ·æ–°æ‰€æœ‰å¸‚åœº
        """
        if market_type is None:
            # åˆ·æ–°æ‰€æœ‰å¸‚åœº
            results = {}
            for mtype in ["china", "hk", "us"]:
                market_name = {"china": "Aè‚¡", "hk": "æ¸¯è‚¡", "us": "ç¾è‚¡"}[mtype]
                logger.info(f"ğŸ”„ å¼ºåˆ¶åˆ·æ–°{market_name}æ•°æ®ç¼“å­˜...")
                self._clear_single_market_cache(mtype)
                results[mtype] = self._fetch_fresh_data_by_type(mtype)
            return results
        else:
            # åˆ·æ–°æŒ‡å®šå¸‚åœº
            market_name = {"china": "Aè‚¡", "hk": "æ¸¯è‚¡", "us": "ç¾è‚¡"}[market_type]
            logger.info(f"ğŸ”„ å¼ºåˆ¶åˆ·æ–°{market_name}æ•°æ®ç¼“å­˜...")
            self._clear_single_market_cache(market_type)
            result = self._fetch_fresh_data_by_type(market_type)
            return {market_type: result}
