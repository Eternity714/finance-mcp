"""
Redis ç¼“å­˜å±‚ï¼Œç”¨äºç¼“å­˜çƒ­ç‚¹å®è§‚æ•°æ®
"""

import json
import pickle
from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta
import logging
import pandas as pd

from ....core.connection_registry import get_connection_registry

logger = logging.getLogger(__name__)


class MacroDataCache:
    """å®è§‚æ•°æ®Redisç¼“å­˜"""

    def __init__(self):
        """åˆå§‹åŒ–ç¼“å­˜"""
        self.connection_registry = get_connection_registry()
        self.cache_prefix = "macro_data:"

        # ç¼“å­˜è¿‡æœŸæ—¶é—´è®¾ç½®ï¼ˆç§’ï¼‰
        self.cache_ttl = {
            "latest_data": 3600,  # æœ€æ–°æ•°æ®ç¼“å­˜1å°æ—¶
            "range_data": 1800,  # èŒƒå›´æ•°æ®ç¼“å­˜30åˆ†é’Ÿ
            "indicator_list": 86400,  # æŒ‡æ ‡åˆ—è¡¨ç¼“å­˜24å°æ—¶
            "sync_status": 300,  # åŒæ­¥çŠ¶æ€ç¼“å­˜5åˆ†é’Ÿ
        }

        logger.info("âœ… MacroDataCache åˆå§‹åŒ–æˆåŠŸ")

    @property
    def redis_client(self):
        """è·å–Rediså®¢æˆ·ç«¯"""
        redis_conn = self.connection_registry.get_redis()
        return redis_conn.get_client() if redis_conn else None

    def _make_key(self, category: str, *args) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_parts = [self.cache_prefix, category] + [str(arg) for arg in args]
        return ":".join(key_parts)

    def _serialize_dataframe(self, df: pd.DataFrame) -> bytes:
        """åºåˆ—åŒ–DataFrame"""
        if df.empty:
            return b""
        return pickle.dumps(df)

    def _deserialize_dataframe(self, data: bytes) -> pd.DataFrame:
        """ååºåˆ—åŒ–DataFrame"""
        if not data:
            return pd.DataFrame()
        try:
            # ç¡®ä¿æ•°æ®æ˜¯bytesç±»å‹
            if isinstance(data, str):
                data = data.encode("utf-8")
            return pickle.loads(data)
        except (pickle.UnpicklingError, UnicodeDecodeError, TypeError) as e:
            logger.error(f"âŒ ååºåˆ—åŒ–DataFrameå¤±è´¥: {e}")
            return pd.DataFrame()
        except Exception as e:
            logger.error(f"âŒ ååºåˆ—åŒ–DataFrameå¤±è´¥: {e}")
            return pd.DataFrame()

    def get_latest_data(
        self, indicator: str, periods: int = 1
    ) -> Optional[pd.DataFrame]:
        """
        è·å–ç¼“å­˜çš„æœ€æ–°æ•°æ®

        Args:
            indicator: æŒ‡æ ‡åç§°
            periods: æœŸæ•°

        Returns:
            DataFrameæˆ–None
        """
        if not self.redis_client:
            return None

        try:
            key = self._make_key("latest", indicator, periods)
            data = self.redis_client.get(key)

            if data:
                df = self._deserialize_dataframe(data)
                logger.debug(f"ğŸ¯ ç¼“å­˜å‘½ä¸­: {indicator} æœ€æ–°{periods}æœŸæ•°æ®")
                return df

            return None

        except Exception as e:
            logger.error(f"âŒ è·å–ç¼“å­˜æ•°æ®å¤±è´¥: {e}")
            return None

    def set_latest_data(self, indicator: str, periods: int, data: pd.DataFrame):
        """
        ç¼“å­˜æœ€æ–°æ•°æ®

        Args:
            indicator: æŒ‡æ ‡åç§°
            periods: æœŸæ•°
            data: æ•°æ®
        """
        if not self.redis_client or data.empty:
            return

        try:
            key = self._make_key("latest", indicator, periods)
            serialized_data = self._serialize_dataframe(data)

            self.redis_client.setex(key, self.cache_ttl["latest_data"], serialized_data)

            logger.debug(f"ğŸ’¾ ç¼“å­˜å·²ä¿å­˜: {indicator} æœ€æ–°{periods}æœŸæ•°æ®")

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç¼“å­˜æ•°æ®å¤±è´¥: {e}")

    def get_range_data(
        self, indicator: str, start_time: str, end_time: str
    ) -> Optional[pd.DataFrame]:
        """
        è·å–ç¼“å­˜çš„èŒƒå›´æ•°æ®

        Args:
            indicator: æŒ‡æ ‡åç§°
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´

        Returns:
            DataFrameæˆ–None
        """
        if not self.redis_client:
            return None

        try:
            key = self._make_key("range", indicator, start_time, end_time)
            data = self.redis_client.get(key)

            if data:
                df = self._deserialize_dataframe(data)
                logger.debug(
                    f"ğŸ¯ ç¼“å­˜å‘½ä¸­: {indicator} {start_time}~{end_time} èŒƒå›´æ•°æ®"
                )
                return df

            return None

        except Exception as e:
            logger.error(f"âŒ è·å–èŒƒå›´ç¼“å­˜æ•°æ®å¤±è´¥: {e}")
            return None

    def set_range_data(
        self, indicator: str, start_time: str, end_time: str, data: pd.DataFrame
    ):
        """
        ç¼“å­˜èŒƒå›´æ•°æ®

        Args:
            indicator: æŒ‡æ ‡åç§°
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            data: æ•°æ®
        """
        if not self.redis_client or data.empty:
            return

        try:
            key = self._make_key("range", indicator, start_time, end_time)
            serialized_data = self._serialize_dataframe(data)

            self.redis_client.setex(key, self.cache_ttl["range_data"], serialized_data)

            logger.debug(f"ğŸ’¾ ç¼“å­˜å·²ä¿å­˜: {indicator} {start_time}~{end_time} èŒƒå›´æ•°æ®")

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜èŒƒå›´ç¼“å­˜æ•°æ®å¤±è´¥: {e}")

    def get_sync_status(self) -> Optional[Dict[str, Any]]:
        """è·å–ç¼“å­˜çš„åŒæ­¥çŠ¶æ€"""
        if not self.redis_client:
            return None

        try:
            key = self._make_key("sync_status")
            data = self.redis_client.get(key)

            if data:
                # ç¡®ä¿æ•°æ®æ˜¯å­—ç¬¦ä¸²æ ¼å¼
                if isinstance(data, bytes):
                    try:
                        data_str = data.decode("utf-8")
                    except UnicodeDecodeError:
                        logger.warning("âš ï¸ åŒæ­¥çŠ¶æ€ç¼“å­˜æ•°æ®æ ¼å¼å¼‚å¸¸ï¼Œæ¸…é™¤ç¼“å­˜")
                        self.redis_client.delete(key)
                        return None
                else:
                    data_str = str(data)

                status = json.loads(data_str)
                logger.debug("ğŸ¯ ç¼“å­˜å‘½ä¸­: åŒæ­¥çŠ¶æ€")
                return status

            return None

        except Exception as e:
            logger.error(f"âŒ è·å–åŒæ­¥çŠ¶æ€ç¼“å­˜å¤±è´¥: {e}")
            return None

    def set_sync_status(self, status: Dict[str, Any]):
        """ç¼“å­˜åŒæ­¥çŠ¶æ€"""
        if not self.redis_client:
            return

        try:
            key = self._make_key("sync_status")
            data = json.dumps(status, ensure_ascii=False, default=str)

            self.redis_client.setex(key, self.cache_ttl["sync_status"], data)

            logger.debug("ğŸ’¾ ç¼“å­˜å·²ä¿å­˜: åŒæ­¥çŠ¶æ€")

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åŒæ­¥çŠ¶æ€ç¼“å­˜å¤±è´¥: {e}")

    def invalidate_indicator(self, indicator: str):
        """
        å¤±æ•ˆæŒ‡å®šæŒ‡æ ‡çš„æ‰€æœ‰ç¼“å­˜

        Args:
            indicator: æŒ‡æ ‡åç§°
        """
        if not self.redis_client:
            return

        try:
            # æŸ¥æ‰¾æ‰€æœ‰ç›¸å…³çš„ç¼“å­˜é”®
            pattern = self._make_key("*", indicator, "*")
            keys = self.redis_client.keys(pattern)

            if keys:
                self.redis_client.delete(*keys)
                logger.info(f"ğŸ—‘ï¸ å·²æ¸…é™¤ {indicator} çš„ {len(keys)} ä¸ªç¼“å­˜")

        except Exception as e:
            logger.error(f"âŒ æ¸…é™¤æŒ‡æ ‡ç¼“å­˜å¤±è´¥: {e}")

    def invalidate_all(self):
        """æ¸…é™¤æ‰€æœ‰å®è§‚æ•°æ®ç¼“å­˜"""
        if not self.redis_client:
            return

        try:
            pattern = self.cache_prefix + "*"
            keys = self.redis_client.keys(pattern)

            if keys:
                self.redis_client.delete(*keys)
                logger.info(f"ğŸ—‘ï¸ å·²æ¸…é™¤æ‰€æœ‰å®è§‚æ•°æ®ç¼“å­˜ ({len(keys)} ä¸ª)")

        except Exception as e:
            logger.error(f"âŒ æ¸…é™¤æ‰€æœ‰ç¼“å­˜å¤±è´¥: {e}")

    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        if not self.redis_client:
            return {"status": "redis_unavailable"}

        try:
            pattern = self.cache_prefix + "*"
            keys = self.redis_client.keys(pattern)

            stats = {"total_keys": len(keys), "categories": {}, "memory_usage_bytes": 0}

            # æŒ‰ç±»åˆ«ç»Ÿè®¡
            for key in keys:
                try:
                    key_str = key.decode("utf-8") if isinstance(key, bytes) else key
                    parts = key_str.split(":")
                    if len(parts) >= 3:
                        category = parts[2]  # macro_data:category:...
                        stats["categories"][category] = (
                            stats["categories"].get(category, 0) + 1
                        )

                    # è®¡ç®—å†…å­˜ä½¿ç”¨ï¼ˆè¿‘ä¼¼ï¼‰
                    memory = self.redis_client.memory_usage(key)
                    if memory:
                        stats["memory_usage_bytes"] += memory

                except Exception:
                    continue

            return stats

        except Exception as e:
            logger.error(f"âŒ è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}
