#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–°é—»æœåŠ¡ - é›†æˆå¤šæ•°æ®æº
æ”¯æŒAè‚¡ã€ç¾è‚¡ã€æ¸¯è‚¡çš„æ–°é—»è·å–ï¼Œæ ¹æ®å¸‚åœºç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ•°æ®æºç»„åˆ

æ•°æ®æºä¼˜å…ˆçº§ç­–ç•¥:
- Aè‚¡: 1. ä¸œæ–¹è´¢å¯Œ(å…è´¹) 2. æ— å¤‡ç”¨
- æ¸¯è‚¡: 1. ä¸œæ–¹è´¢å¯Œ 2. FinnHub
- ç¾è‚¡: 1. FinnHub 2. Alpha Vantage 3. NewsAPI

ç‰¹ç‚¹:
- è‡ªåŠ¨æ ¹æ®å¸‚åœºç±»å‹é€‰æ‹©æ•°æ®æº
- æ”¯æŒå¤šæ•°æ®æºå¹¶è¡Œè·å–å’Œåˆå¹¶
- æ™ºèƒ½å»é‡å’Œä¼˜å…ˆçº§æ’åº
- ç»Ÿä¸€çš„æ•°æ®è¿”å›æ ¼å¼
"""

import os
import requests
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).resolve().parents[3]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# å¯¼å…¥é…ç½®
from src.config.settings import get_settings

# å¯¼å…¥æœåŠ¡
from src.server.services.akshare_service import AkshareService

# å¯¼å…¥å·¥å…·
from src.server.utils.symbol_processor import get_symbol_processor

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("new_service")


@dataclass
class NewsArticle:
    """ç»Ÿä¸€çš„æ–°é—»æ–‡ç« æ•°æ®ç»“æ„"""

    title: str
    content: str
    source: str  # æ•°æ®æºåç§°: FinnHub, AlphaVantage, NewsAPI, EastMoney
    publish_time: str  # ISOæ ¼å¼æ—¶é—´å­—ç¬¦ä¸²
    url: str
    symbol: str  # ç›¸å…³è‚¡ç¥¨ä»£ç 
    relevance_score: float = 0.0  # ç›¸å…³æ€§è¯„åˆ† 0-1
    sentiment: str = "neutral"  # positive, negative, neutral

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return asdict(self)


class NewsDataSource:
    """æ–°é—»æ•°æ®æºåŸºç±»"""

    def __init__(self, name: str, enabled: bool = True):
        self.name = name
        self.enabled = enabled
        self.settings = get_settings()

    def is_available(self) -> bool:
        """æ£€æŸ¥æ•°æ®æºæ˜¯å¦å¯ç”¨"""
        return self.enabled

    def fetch_news(
        self, symbol: str, start_date: datetime, end_date: datetime
    ) -> List[NewsArticle]:
        """è·å–æ–°é—»æ•°æ® - å­ç±»å®ç°"""
        raise NotImplementedError


class FinnHubNewsSource(NewsDataSource):
    """FinnHub æ–°é—»æ•°æ®æº"""

    def __init__(self):
        super().__init__("FinnHub")
        self.api_key = os.getenv("FINNHUB_API_KEY", "")
        self.enabled = bool(self.api_key)

    def is_available(self) -> bool:
        return self.enabled and bool(self.api_key)

    def fetch_news(
        self, symbol: str, start_date: datetime, end_date: datetime
    ) -> List[NewsArticle]:
        """ä» FinnHub è·å–æ–°é—»"""
        if not self.is_available():
            logger.warning(f"[{self.name}] APIå¯†é’¥æœªé…ç½®ï¼Œè·³è¿‡")
            return []

        logger.info(
            f"[{self.name}] è·å– {symbol} çš„æ–°é—»: {start_date.date()} åˆ° {end_date.date()}"
        )

        url = "https://finnhub.io/api/v1/company-news"
        params = {
            "symbol": symbol,
            "from": start_date.strftime("%Y-%m-%d"),
            "to": end_date.strftime("%Y-%m-%d"),
            "token": self.api_key,
        }

        try:
            response = requests.get(url, params=params, timeout=10)

            if response.status_code == 200:
                data = response.json()
                if not data:
                    logger.info(f"[{self.name}] æœªæ‰¾åˆ° {symbol} çš„æ–°é—»æ•°æ®")
                    return []

                news_list = []
                for item in data:
                    try:
                        news = NewsArticle(
                            title=item.get("headline", ""),
                            content=item.get("summary", ""),
                            source=self.name,
                            publish_time=datetime.fromtimestamp(
                                item.get("datetime", 0)
                            ).isoformat(),
                            url=item.get("url", ""),
                            symbol=symbol,
                            relevance_score=0.8,  # FinnHubæ•°æ®è´¨é‡è¾ƒé«˜
                        )
                        news_list.append(news)
                    except Exception as e:
                        logger.warning(f"[{self.name}] è§£ææ–°é—»é¡¹å¤±è´¥: {e}")
                        continue

                logger.info(f"[{self.name}] âœ… è·å–åˆ° {len(news_list)} æ¡æ–°é—»")
                return news_list

            elif response.status_code == 401:
                logger.error(f"[{self.name}] APIå¯†é’¥æ— æ•ˆ")
                return []
            else:
                logger.error(f"[{self.name}] è¯·æ±‚å¤±è´¥: {response.status_code}")
                return []

        except Exception as e:
            logger.error(f"[{self.name}] è¯·æ±‚å¼‚å¸¸: {e}")
            return []


class AlphaVantageNewsSource(NewsDataSource):
    """Alpha Vantage æ–°é—»æ•°æ®æº"""

    def __init__(self):
        super().__init__("AlphaVantage")
        self.api_key = os.getenv("ALPHA_VANTAGE_API_KEY", "")
        self.enabled = bool(self.api_key)

    def is_available(self) -> bool:
        return self.enabled and bool(self.api_key)

    def fetch_news(
        self, symbol: str, start_date: datetime, end_date: datetime
    ) -> List[NewsArticle]:
        """ä» Alpha Vantage è·å–æ–°é—»"""
        if not self.is_available():
            logger.warning(f"[{self.name}] APIå¯†é’¥æœªé…ç½®ï¼Œè·³è¿‡")
            return []

        logger.info(
            f"[{self.name}] è·å– {symbol} çš„æ–°é—»: {start_date.date()} åˆ° {end_date.date()}"
        )

        url = "https://www.alphavantage.co/query"
        params = {
            "function": "NEWS_SENTIMENT",
            "tickers": symbol,
            "apikey": self.api_key,
            "limit": 100,
        }

        try:
            response = requests.get(url, params=params, timeout=10)

            if response.status_code == 200:
                data = response.json()

                if "feed" not in data:
                    logger.info(f"[{self.name}] æœªæ‰¾åˆ° {symbol} çš„æ–°é—»æ•°æ®")
                    return []

                news_list = []
                for item in data.get("feed", []):
                    try:
                        # è§£ææ—¶é—´
                        time_str = item.get("time_published", "")
                        if time_str:
                            pub_time = datetime.strptime(time_str, "%Y%m%dT%H%M%S")
                        else:
                            pub_time = datetime.now()

                        # è¿‡æ»¤æ—¶é—´èŒƒå›´
                        if not (start_date <= pub_time <= end_date):
                            continue

                        # è·å–æƒ…æ„Ÿåˆ†æ
                        sentiment_score = item.get("overall_sentiment_score", 0)
                        if sentiment_score > 0.15:
                            sentiment = "positive"
                        elif sentiment_score < -0.15:
                            sentiment = "negative"
                        else:
                            sentiment = "neutral"

                        news = NewsArticle(
                            title=item.get("title", ""),
                            content=item.get("summary", ""),
                            source=self.name,
                            publish_time=pub_time.isoformat(),
                            url=item.get("url", ""),
                            symbol=symbol,
                            relevance_score=abs(sentiment_score),
                            sentiment=sentiment,
                        )
                        news_list.append(news)

                    except Exception as e:
                        logger.warning(f"[{self.name}] è§£ææ–°é—»é¡¹å¤±è´¥: {e}")
                        continue

                logger.info(f"[{self.name}] âœ… è·å–åˆ° {len(news_list)} æ¡æ–°é—»")
                return news_list
            else:
                logger.error(f"[{self.name}] è¯·æ±‚å¤±è´¥: {response.status_code}")
                return []

        except Exception as e:
            logger.error(f"[{self.name}] è¯·æ±‚å¼‚å¸¸: {e}")
            return []


class NewsAPISource(NewsDataSource):
    """NewsAPI æ–°é—»æ•°æ®æº"""

    def __init__(self, use_proxy: bool = False):
        super().__init__("NewsAPI")
        self.api_key = os.getenv("NEWSAPI_KEY", "")
        self.enabled = bool(self.api_key)
        self.proxies = None

        if use_proxy:
            self.proxies = {
                "http": "http://127.0.0.1:7890",
                "https": "http://127.0.0.1:7890",
            }

    def is_available(self) -> bool:
        return self.enabled and bool(self.api_key)

    def fetch_news(
        self, symbol: str, start_date: datetime, end_date: datetime
    ) -> List[NewsArticle]:
        """ä» NewsAPI è·å–æ–°é—»"""
        if not self.is_available():
            logger.warning(f"[{self.name}] APIå¯†é’¥æœªé…ç½®ï¼Œè·³è¿‡")
            return []

        # NewsAPI å…è´¹ç‰ˆåªæ”¯æŒæœ€è¿‘30å¤©
        days_diff = (end_date - start_date).days
        if days_diff > 30:
            logger.warning(f"[{self.name}] å…è´¹ç‰ˆä»…æ”¯æŒ30å¤©å†…æ•°æ®ï¼Œè°ƒæ•´æŸ¥è¯¢èŒƒå›´")
            start_date = end_date - timedelta(days=30)

        logger.info(
            f"[{self.name}] è·å– {symbol} çš„æ–°é—»: {start_date.date()} åˆ° {end_date.date()}"
        )

        # æ„å»ºæŸ¥è¯¢å…³é”®è¯
        query = f"{symbol}"

        url = "https://newsapi.org/v2/everything"
        params = {
            "q": query,
            "language": "en",
            "sortBy": "publishedAt",
            "from": start_date.strftime("%Y-%m-%d"),
            "to": end_date.strftime("%Y-%m-%d"),
            "apiKey": self.api_key,
        }

        try:
            response = requests.get(
                url, params=params, proxies=self.proxies, timeout=10
            )

            if response.status_code == 200:
                data = response.json()

                if data.get("status") != "ok" or not data.get("articles"):
                    logger.info(f"[{self.name}] æœªæ‰¾åˆ° {symbol} çš„æ–°é—»æ•°æ®")
                    return []

                news_list = []
                for item in data.get("articles", []):
                    try:
                        pub_time_str = item.get("publishedAt", "")
                        if pub_time_str:
                            pub_time = datetime.fromisoformat(
                                pub_time_str.replace("Z", "+00:00")
                            )
                        else:
                            pub_time = datetime.now()

                        news = NewsArticle(
                            title=item.get("title", ""),
                            content=item.get("description", "")
                            or item.get("content", ""),
                            source=self.name,
                            publish_time=pub_time.isoformat(),
                            url=item.get("url", ""),
                            symbol=symbol,
                            relevance_score=0.7,
                        )
                        news_list.append(news)

                    except Exception as e:
                        logger.warning(f"[{self.name}] è§£ææ–°é—»é¡¹å¤±è´¥: {e}")
                        continue

                logger.info(f"[{self.name}] âœ… è·å–åˆ° {len(news_list)} æ¡æ–°é—»")
                return news_list

            elif response.status_code == 426:
                logger.warning(f"[{self.name}] éœ€è¦å‡çº§è®¢é˜…ä»¥è®¿é—®å†å²æ•°æ®")
                return []
            else:
                logger.error(f"[{self.name}] è¯·æ±‚å¤±è´¥: {response.status_code}")
                return []

        except Exception as e:
            logger.error(f"[{self.name}] è¯·æ±‚å¼‚å¸¸: {e}")
            return []


class EastMoneyNewsSource(NewsDataSource):
    """ä¸œæ–¹è´¢å¯Œ(AkShare) æ–°é—»æ•°æ®æº"""

    def __init__(self):
        super().__init__("EastMoney")
        self.akshare_service = AkshareService()
        self.enabled = True  # å…è´¹æœåŠ¡ï¼Œé»˜è®¤å¯ç”¨

    def is_available(self) -> bool:
        return self.enabled

    def fetch_news(
        self, symbol: str, start_date: datetime, end_date: datetime
    ) -> List[NewsArticle]:
        """ä»ä¸œæ–¹è´¢å¯Œè·å–æ–°é—»"""
        logger.info(
            f"[{self.name}] è·å– {symbol} çš„æ–°é—»: {start_date.date()} åˆ° {end_date.date()}"
        )

        try:
            # è·å–æ–°é—»æ•°æ®
            df = self.akshare_service.get_stock_news_em(symbol, max_news=100)

            if df is None or df.empty:
                logger.info(f"[{self.name}] æœªæ‰¾åˆ° {symbol} çš„æ–°é—»æ•°æ®")
                return []

            # æŸ¥æ‰¾æ—¶é—´åˆ—
            time_column = None
            for col in ["å‘å¸ƒæ—¶é—´", "æ—¶é—´", "æ—¥æœŸ", "date", "publish_time"]:
                if col in df.columns:
                    time_column = col
                    break

            if not time_column:
                logger.warning(
                    f"[{self.name}] æœªæ‰¾åˆ°æ—¶é—´åˆ—ï¼Œå¯ç”¨åˆ—: {df.columns.tolist()}"
                )
                return []

            # è¿‡æ»¤æ—¶é—´èŒƒå›´
            news_list = []
            for _, row in df.iterrows():
                try:
                    # è§£ææ—¶é—´
                    time_str = str(row[time_column])
                    try:
                        pub_time = pd.to_datetime(time_str)
                    except Exception:
                        # å°è¯•å…¶ä»–æ ¼å¼
                        pub_time = datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S")

                    # æ—¶åŒºå¤„ç†
                    if pub_time.tzinfo is None:
                        pub_time = pub_time.replace(tzinfo=None)
                    else:
                        pub_time = pub_time.replace(tzinfo=None)

                    # è¿‡æ»¤æ—¶é—´èŒƒå›´
                    if not (start_date <= pub_time <= end_date):
                        continue

                    # æå–æ ‡é¢˜å’Œå†…å®¹ (ä½¿ç”¨ä¸œæ–¹è´¢å¯Œçš„å®é™…åˆ—å)
                    title = str(
                        row.get("æ–°é—»æ ‡é¢˜", row.get("æ ‡é¢˜", row.get("title", "")))
                    )
                    content = str(
                        row.get("æ–°é—»å†…å®¹", row.get("å†…å®¹", row.get("content", "")))
                    )
                    url = str(row.get("æ–°é—»é“¾æ¥", row.get("é“¾æ¥", row.get("url", ""))))

                    news = NewsArticle(
                        title=title,
                        content=content,
                        source=self.name,
                        publish_time=pub_time.isoformat(),
                        url=url,
                        symbol=symbol,
                        relevance_score=0.9,  # ä¸œæ–¹è´¢å¯Œé’ˆå¯¹æ€§å¼º
                    )
                    news_list.append(news)

                except Exception as e:
                    logger.warning(f"[{self.name}] è§£ææ–°é—»é¡¹å¤±è´¥: {e}")
                    continue

            logger.info(f"[{self.name}] âœ… è·å–åˆ° {len(news_list)} æ¡æ–°é—»")
            return news_list

        except Exception as e:
            logger.error(f"[{self.name}] è¯·æ±‚å¼‚å¸¸: {e}")
            return []


class MultiSourceNewsService:
    """å¤šæ•°æ®æºæ–°é—»æœåŠ¡"""

    def __init__(self, use_proxy_for_newsapi: bool = False):
        """
        åˆå§‹åŒ–å¤šæ•°æ®æºæ–°é—»æœåŠ¡

        Args:
            use_proxy_for_newsapi: NewsAPIæ˜¯å¦ä½¿ç”¨ä»£ç†
        """
        self.symbol_processor = get_symbol_processor()

        # åˆå§‹åŒ–æ‰€æœ‰æ•°æ®æº
        self.sources = {
            "finnhub": FinnHubNewsSource(),
            "alphavantage": AlphaVantageNewsSource(),
            "newsapi": NewsAPISource(use_proxy=use_proxy_for_newsapi),
            "eastmoney": EastMoneyNewsSource(),
        }

        # æ•°æ®æºä¼˜å…ˆçº§ç­–ç•¥
        self.priority_strategy = {
            "Aè‚¡": ["eastmoney"],  # åªæœ‰ä¸œæ–¹è´¢å¯Œæ”¯æŒ
            "æ¸¯è‚¡": ["eastmoney", "finnhub"],  # ä¸œæ–¹è´¢å¯Œä¼˜å…ˆï¼ŒFinnHubå¤‡ç”¨
            "ç¾è‚¡": ["finnhub", "alphavantage", "newsapi"],  # FinnHubæœ€ä¼˜
        }

        logger.info("âœ… å¤šæ•°æ®æºæ–°é—»æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        self._log_available_sources()

    def _log_available_sources(self):
        """è®°å½•å¯ç”¨æ•°æ®æº"""
        available = [
            name for name, source in self.sources.items() if source.is_available()
        ]
        unavailable = [
            name for name, source in self.sources.items() if not source.is_available()
        ]

        if available:
            logger.info(f"âœ… å¯ç”¨æ•°æ®æº: {', '.join(available)}")
        if unavailable:
            logger.warning(f"âš ï¸ ä¸å¯ç”¨æ•°æ®æº: {', '.join(unavailable)}")

    def get_news_for_date(
        self, symbol: str, target_date: Optional[str] = None, days_before: int = 30
    ) -> Dict:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„è‚¡ç¥¨æ–°é—»

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            target_date: ç›®æ ‡æ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºå½“å‰æ—¥æœŸ
            days_before: å‘å‰æŸ¥è¯¢çš„å¤©æ•°ï¼Œé»˜è®¤30å¤©

        Returns:
            Dict: åŒ…å«æ–°é—»åˆ—è¡¨å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        # å¤„ç†ç›®æ ‡æ—¥æœŸ
        if target_date:
            try:
                end_date = datetime.strptime(target_date, "%Y-%m-%d")
            except ValueError:
                logger.error(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {target_date}ï¼Œåº”ä¸º YYYY-MM-DD")
                return {
                    "success": False,
                    "error": "æ—¥æœŸæ ¼å¼é”™è¯¯",
                    "symbol": symbol,
                }
        else:
            end_date = datetime.now()

        # è®¡ç®—å¼€å§‹æ—¥æœŸ
        start_date = end_date - timedelta(days=days_before)

        return self.get_news(symbol, start_date, end_date)

    def get_news(self, symbol: str, start_date: datetime, end_date: datetime) -> Dict:
        """
        è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„è‚¡ç¥¨æ–°é—»

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            Dict: åŒ…å«æ–°é—»åˆ—è¡¨å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        # åˆ†æè‚¡ç¥¨ä»£ç 
        symbol_info = self.symbol_processor.process_symbol(symbol)
        market = symbol_info["market"]

        logger.info("=" * 80)
        logger.info(f"ğŸ“° è·å–æ–°é—»: {symbol} ({market})")
        logger.info(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date.date()} åˆ° {end_date.date()}")
        logger.info("=" * 80)

        # è·å–è¯¥å¸‚åœºçš„æ•°æ®æºä¼˜å…ˆçº§åˆ—è¡¨
        source_priority = self.priority_strategy.get(market, [])

        if not source_priority:
            logger.warning(f"âš ï¸ å¸‚åœº {market} æ²¡æœ‰é…ç½®æ•°æ®æº")
            return {
                "success": False,
                "error": f"ä¸æ”¯æŒçš„å¸‚åœº: {market}",
                "symbol": symbol,
                "market": market,
            }

        # æ ¹æ®å¸‚åœºé€‰æ‹©åˆé€‚çš„è‚¡ç¥¨ä»£ç æ ¼å¼
        formatted_symbols = self._get_formatted_symbols(
            symbol, symbol_info, source_priority
        )

        # å¹¶è¡Œè·å–æ‰€æœ‰æ•°æ®æºçš„æ–°é—»
        all_news = self._fetch_from_multiple_sources(
            source_priority, formatted_symbols, start_date, end_date
        )

        # å»é‡å’Œæ’åº
        unique_news = self._deduplicate_news(all_news)
        sorted_news = sorted(unique_news, key=lambda x: x.publish_time, reverse=True)

        # ç»Ÿè®¡ä¿¡æ¯
        source_stats = {}
        for news in sorted_news:
            source_stats[news.source] = source_stats.get(news.source, 0) + 1

        logger.info("=" * 80)
        logger.info(f"âœ… æ–°é—»è·å–å®Œæˆ: å…± {len(sorted_news)} æ¡")
        for source, count in source_stats.items():
            logger.info(f"   - {source}: {count} æ¡")
        logger.info("=" * 80)

        return {
            "success": True,
            "symbol": symbol,
            "market": market,
            "start_date": start_date.isoformat(),
            "end_date": end_date.isoformat(),
            "total_count": len(sorted_news),
            "source_stats": source_stats,
            "news": [news.to_dict() for news in sorted_news],
        }

    def _get_formatted_symbols(
        self, original_symbol: str, symbol_info: Dict, source_priority: List[str]
    ) -> Dict[str, str]:
        """
        æ ¹æ®æ•°æ®æºéœ€æ±‚æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç 

        Returns:
            Dict: {source_name: formatted_symbol}
        """
        formatted = {}
        formats = symbol_info["formats"]

        for source_name in source_priority:
            if source_name == "finnhub":
                formatted[source_name] = formats[
                    "yfinance"
                ]  # FinnHubä½¿ç”¨ç±»ä¼¼yfinanceæ ¼å¼
            elif source_name == "alphavantage":
                formatted[source_name] = formats["yfinance"]
            elif source_name == "newsapi":
                formatted[source_name] = formats["news_api"]
            elif source_name == "eastmoney":
                formatted[source_name] = formats["akshare"]
            else:
                formatted[source_name] = original_symbol

        logger.info(f"ğŸ“ ä»£ç æ ¼å¼åŒ–: {formatted}")
        return formatted

    def _fetch_from_multiple_sources(
        self,
        source_names: List[str],
        formatted_symbols: Dict[str, str],
        start_date: datetime,
        end_date: datetime,
    ) -> List[NewsArticle]:
        """
        å¹¶è¡Œä»å¤šä¸ªæ•°æ®æºè·å–æ–°é—»

        Args:
            source_names: æ•°æ®æºåç§°åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
            formatted_symbols: æ ¼å¼åŒ–åçš„è‚¡ç¥¨ä»£ç å­—å…¸
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            List[NewsArticle]: æ‰€æœ‰æ•°æ®æºçš„æ–°é—»åˆ—è¡¨
        """
        all_news = []

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè·å–
        with ThreadPoolExecutor(max_workers=len(source_names)) as executor:
            future_to_source = {}

            for source_name in source_names:
                source = self.sources.get(source_name)
                if not source or not source.is_available():
                    logger.warning(f"âš ï¸ æ•°æ®æº {source_name} ä¸å¯ç”¨ï¼Œè·³è¿‡")
                    continue

                symbol = formatted_symbols.get(source_name, "")
                future = executor.submit(
                    source.fetch_news, symbol, start_date, end_date
                )
                future_to_source[future] = source_name

            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_source):
                source_name = future_to_source[future]
                try:
                    news_list = future.result()
                    all_news.extend(news_list)
                except Exception as e:
                    logger.error(f"âŒ æ•°æ®æº {source_name} è·å–å¤±è´¥: {e}")

        return all_news

    def _deduplicate_news(self, news_list: List[NewsArticle]) -> List[NewsArticle]:
        """
        æ–°é—»å»é‡

        ç­–ç•¥:
        1. ä¼˜å…ˆåŸºäºURLå»é‡
        2. å…¶æ¬¡åŸºäºæ ‡é¢˜+å‘å¸ƒæ—¶é—´ç»„åˆå»é‡
        3. ä¿ç•™æœ‰æ ‡é¢˜çš„æ–°é—»
        """
        if not news_list:
            return []

        unique_news = []
        seen_urls = set()
        seen_combinations = set()

        for news in news_list:
            # ç­–ç•¥1: URLå»é‡ï¼ˆæœ€å¯é ï¼‰
            if news.url and news.url.strip():
                url_key = news.url.strip().lower()
                if url_key in seen_urls:
                    continue
                seen_urls.add(url_key)

            # ç­–ç•¥2: æ ‡é¢˜+æ—¶é—´ç»„åˆå»é‡
            title_key = news.title.lower().strip()
            time_key = news.publish_time[:10] if news.publish_time else ""
            combination_key = f"{title_key}|{time_key}"

            # è·³è¿‡ç©ºæ ‡é¢˜æˆ–å·²è§è¿‡çš„ç»„åˆ
            if not title_key or combination_key in seen_combinations:
                continue

            seen_combinations.add(combination_key)
            unique_news.append(news)

        logger.info(f"ğŸ“Š å»é‡: {len(news_list)} æ¡ -> {len(unique_news)} æ¡")
        return unique_news


# ============ ä¾¿æ·å‡½æ•° ============


def get_news_service(use_proxy: bool = False) -> MultiSourceNewsService:
    """
    è·å–æ–°é—»æœåŠ¡å®ä¾‹

    Args:
        use_proxy: NewsAPIæ˜¯å¦ä½¿ç”¨ä»£ç†

    Returns:
        MultiSourceNewsService: æ–°é—»æœåŠ¡å®ä¾‹
    """
    return MultiSourceNewsService(use_proxy_for_newsapi=use_proxy)


def get_stock_news(
    symbol: str,
    target_date: Optional[str] = None,
    days_before: int = 30,
    use_proxy: bool = False,
) -> Dict:
    """
    è·å–è‚¡ç¥¨æ–°é—»çš„ä¾¿æ·å‡½æ•°

    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        target_date: ç›®æ ‡æ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºå½“å‰æ—¥æœŸ
        days_before: å‘å‰æŸ¥è¯¢çš„å¤©æ•°ï¼Œé»˜è®¤30å¤©
        use_proxy: NewsAPIæ˜¯å¦ä½¿ç”¨ä»£ç†

    Returns:
        Dict: æ–°é—»æ•°æ®
    """
    service = get_news_service(use_proxy=use_proxy)
    return service.get_news_for_date(symbol, target_date, days_before)


def get_stock_news_range(
    symbol: str, start_date: str, end_date: str, use_proxy: bool = False
) -> Dict:
    """
    è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„è‚¡ç¥¨æ–°é—»

    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        use_proxy: NewsAPIæ˜¯å¦ä½¿ç”¨ä»£ç†

    Returns:
        Dict: æ–°é—»æ•°æ®
    """
    try:
        start = datetime.strptime(start_date, "%Y-%m-%d")
        end = datetime.strptime(end_date, "%Y-%m-%d")
    except ValueError as e:
        logger.error(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {e}")
        return {
            "success": False,
            "error": "æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œåº”ä¸º YYYY-MM-DD",
        }

    service = get_news_service(use_proxy=use_proxy)
    return service.get_news(symbol, start, end)
